{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bafbfe",
   "metadata": {},
   "source": [
    "# Laboratorio 4: Modelos CNN #\n",
    "*Maria-Ignacia Rojas*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e56853",
   "metadata": {},
   "source": [
    "1. Implementar e evaluar el desempeño de una red neuronal U-net en el problema de segmentación de esclerosis múltiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e774fe6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL). Error loading \"C:\\Users\\miroj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:281\u001b[39m\n\u001b[32m    277\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    279\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:264\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    260\u001b[39m     err = ctypes.WinError(last_error)\n\u001b[32m    261\u001b[39m     err.strerror += (\n\u001b[32m    262\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Error loading \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m or one of its dependencies.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    263\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    266\u001b[39m     is_loaded = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [WinError 1114] Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL). Error loading \"C:\\Users\\miroj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f41ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MSDataset(Dataset):\n",
    "    def __init__(self, base_dir):\n",
    "        self.samples = []\n",
    "        self.size = (192, 192)\n",
    "        self.base_dir = base_dir\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        patients = sorted([p for p in os.listdir(self.base_dir) if p.startswith(\"patient_\")])\n",
    "        print(\"Cargando pacientes:\", patients)\n",
    "\n",
    "        for p in patients:\n",
    "            p_path = os.path.join(self.base_dir, p)\n",
    "            flair = os.path.join(p_path, \"FLAIR.nii.gz\")\n",
    "            t1 = os.path.join(p_path, \"T1W.nii.gz\")\n",
    "            t1ce = os.path.join(p_path, \"T1WKS.nii.gz\")\n",
    "            t2 = os.path.join(p_path, \"T2W.nii.gz\")\n",
    "            mask = os.path.join(p_path, \"consensus_gt.nii.gz\")\n",
    "\n",
    "            if not all(os.path.exists(f) for f in [flair, t1, t1ce, t2, mask]):\n",
    "                continue\n",
    "\n",
    "            # Cargar todas las modalidades\n",
    "            flair_nii = nib.load(flair).get_fdata()\n",
    "            t1_nii = nib.load(t1).get_fdata()\n",
    "            t1ce_nii = nib.load(t1ce).get_fdata()\n",
    "            t2_nii = nib.load(t2).get_fdata()\n",
    "            mask_nii = nib.load(mask).get_fdata()\n",
    "\n",
    "            # Reescalar todas al tamaño de FLAIR\n",
    "            target_shape = flair_nii.shape\n",
    "            def resize_volume(vol, target_shape):\n",
    "                vol_t = torch.tensor(vol).unsqueeze(0).unsqueeze(0).float()\n",
    "                resized = F.interpolate(vol_t, size=target_shape, mode='trilinear', align_corners=False)\n",
    "                return resized[0,0].numpy()\n",
    "\n",
    "            t1_nii   = resize_volume(t1_nii, target_shape)\n",
    "            t1ce_nii = resize_volume(t1ce_nii, target_shape)\n",
    "            t2_nii   = resize_volume(t2_nii, target_shape)\n",
    "            mask_nii = resize_volume(mask_nii, target_shape)\n",
    "\n",
    "            for i in range(target_shape[2]):\n",
    "                img = np.stack([\n",
    "                    flair_nii[:, :, i],\n",
    "                    t1_nii[:, :, i],\n",
    "                    t1ce_nii[:, :, i],\n",
    "                    t2_nii[:, :, i]\n",
    "                ], axis=0)\n",
    "\n",
    "                msk = mask_nii[:, :, i]\n",
    "                if msk.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                img = self.normalize(img)\n",
    "                img, msk = self.resize_with_padding(img, msk)\n",
    "                self.samples.append((img, msk))\n",
    "\n",
    "        print(f\"Dataset creado con {len(self.samples)} cortes útiles.\")\n",
    "\n",
    "    def normalize(self, img):\n",
    "        img = (img - np.mean(img)) / (np.std(img) + 1e-8)\n",
    "        return img\n",
    "\n",
    "    def resize_with_padding(self, img, mask):\n",
    "        target_h, target_w = self.size\n",
    "        c, h, w = img.shape\n",
    "\n",
    "        scale = min(target_h / h, target_w / w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "\n",
    "        img_resized = F.interpolate(\n",
    "            torch.tensor(img).unsqueeze(0),\n",
    "            size=(new_h, new_w),\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )[0].numpy()\n",
    "\n",
    "        mask_resized = F.interpolate(\n",
    "            torch.tensor(mask).unsqueeze(0).unsqueeze(0),\n",
    "            size=(new_h, new_w),\n",
    "            mode='nearest'\n",
    "        )[0, 0].numpy()\n",
    "\n",
    "        pad_h = (target_h - new_h) // 2\n",
    "        pad_w = (target_w - new_w) // 2\n",
    "\n",
    "        img_padded = np.pad(img_resized, ((0, 0), (pad_h, target_h - new_h - pad_h),\n",
    "                                          (pad_w, target_w - new_w - pad_w)))\n",
    "        mask_padded = np.pad(mask_resized, ((pad_h, target_h - new_h - pad_h),\n",
    "                                            (pad_w, target_w - new_w - pad_w)))\n",
    "\n",
    "        return img_padded, mask_padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a56216",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"C:\\Users\\miroj\\Downloads\\data\"\n",
    "ds = MSDataset(base_dir)\n",
    "\n",
    "x, y = ds[0]\n",
    "print(\"Shape entrada:\", x.shape)\n",
    "print(\"Shape máscara:\", y.shape)\n",
    "print(\"Suma máscara:\", y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_ch=4, out_ch=1):\n",
    "        super().__init__()\n",
    "        self.d1 = DoubleConv(in_ch, 64)\n",
    "        self.d2 = DoubleConv(64, 128)\n",
    "        self.d3 = DoubleConv(128, 256)\n",
    "        self.d4 = DoubleConv(256, 512)\n",
    "        self.bottom = DoubleConv(512, 1024)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.uconv4 = DoubleConv(1024, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.uconv3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.uconv2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.uconv1 = DoubleConv(128, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.d1(x)\n",
    "        x2 = self.d2(F.max_pool2d(x1, 2))\n",
    "        x3 = self.d3(F.max_pool2d(x2, 2))\n",
    "        x4 = self.d4(F.max_pool2d(x3, 2))\n",
    "        x5 = self.bottom(F.max_pool2d(x4, 2))\n",
    "\n",
    "        x = self.up4(x5)\n",
    "        x = self.uconv4(torch.cat([x, x4], dim=1))\n",
    "        x = self.up3(x)\n",
    "        x = self.uconv3(torch.cat([x, x3], dim=1))\n",
    "        x = self.up2(x)\n",
    "        x = self.uconv2(torch.cat([x, x2], dim=1))\n",
    "        x = self.up1(x)\n",
    "        x = self.uconv1(torch.cat([x, x1], dim=1))\n",
    "        return torch.sigmoid(self.out_conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"C:\\Users\\miroj\\Downloads\\data\"\n",
    "ds = MSDataset(base_dir)\n",
    "dl = DataLoader(ds, batch_size=2, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando:\", device)\n",
    "model = UNet2D().to(device)\n",
    "\n",
    "criterion = lambda pred, target: 0.5 * F.binary_cross_entropy(pred, target) + \\\n",
    "                                 0.5 * (1 - (2 * (pred * target).sum() + 1e-8) /\n",
    "                                        (pred.sum() + target.sum() + 1e-8))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 10 \n",
    "\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dl, desc=f\"Época {epoch+1}/{n_epochs}\", unit=\"batch\")\n",
    "\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / len(dl)\n",
    "    print(f\"Época {epoch+1}/{n_epochs} - Pérdida promedio: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar modelo entrenado\n",
    "torch.save(model.state_dict(), \"unet_brain.pt\")\n",
    "print(\"Modelo guardado como unet_brain.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_prediccion_simple(model, dataset, device, index):\n",
    "    \"\"\"\n",
    "    Muestra 3 imágenes: Original (FLAIR), Máscara Verdadera (GT) y Predicción.\n",
    "    \"\"\"\n",
    "    print(f\"Generando gráfico para el índice: {index}\")\n",
    "    \n",
    "    model.eval() \n",
    "    \n",
    "    try:\n",
    "        x, y = dataset[index]\n",
    "    except IndexError:\n",
    "        print(f\"Error: El índice {index} está fuera de rango.\")\n",
    "        return\n",
    "\n",
    "    x_tensor = x.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        pred_tensor = model(x_tensor)\n",
    "\n",
    "    x_np = x.cpu().numpy()\n",
    "    y_np = y.squeeze(0).cpu().numpy() \n",
    "    \n",
    "    pred_np = (pred_tensor.squeeze(0).squeeze(0).cpu().numpy() > 0.5).astype(float)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 6)) \n",
    "    axes[0].imshow(x_np[0], cmap='gray')\n",
    "    axes[0].set_title(f'Original (FLAIR) - Corte {index}')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(y_np, cmap='gray')\n",
    "    axes[1].set_title('Máscara Verdadera (GT)')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(pred_np, cmap='gray') \n",
    "    axes[2].set_title('Predicción del Modelo')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "visualizar_prediccion_simple(model, ds, device, index=25)\n",
    "\n",
    "visualizar_prediccion_simple(model, ds, device, index=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8de828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.eval() \n",
    "\n",
    "def calcular_metricas(pred_tensor, target_tensor, threshold=0.5, epsilon=1e-6):\n",
    "    pred_bin = (pred_tensor > threshold).float()\n",
    "    target_bin = (target_tensor == 1).float()\n",
    "    \n",
    "    # Calcular TP, FP, FN, TN\n",
    "    tp = (pred_bin * target_bin).sum()\n",
    "    fp = (pred_bin * (1 - target_bin)).sum()\n",
    "    fn = ((1 - pred_bin) * target_bin).sum()\n",
    "    tn = ((1 - pred_bin) * (1 - target_bin)).sum()\n",
    "    \n",
    "    dice = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
    "    iou = tp / (tp + fp + fn + epsilon)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + epsilon)\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    specificity = tn / (tn + fp + epsilon)\n",
    "    \n",
    "    metrics = {\n",
    "        \"dice\": dice.item(),\n",
    "        \"iou\": iou.item(),\n",
    "        \"accuracy\": accuracy.item(),\n",
    "        \"precision\": precision.item(),\n",
    "        \"recall_sensitivity\": recall.item(),\n",
    "        \"specificity\": specificity.item()\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def evaluar_modelo(model, dataset, device, batch_size=8):\n",
    "\n",
    "    dl_eval = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval() \n",
    "    \n",
    "    all_metrics = {\n",
    "        \"dice\": [], \"iou\": [], \"accuracy\": [],\n",
    "        \"precision\": [], \"recall_sensitivity\": [], \"specificity\": []\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(dl_eval, desc=\"Calculando Métricas\"):\n",
    "            \n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device) \n",
    "            \n",
    "            pred_batch = model(x_batch)\n",
    "            \n",
    "            for i in range(pred_batch.shape[0]):\n",
    "                pred_i = pred_batch[i] # Predicción para la imagen i\n",
    "                y_i = y_batch[i]       # Máscara real para la imagen i\n",
    "                \n",
    "                metrics = calcular_metricas(pred_i, y_i)\n",
    "                for key, value in metrics.items():\n",
    "                    all_metrics[key].append(value)\n",
    "\n",
    "    avg_metrics = {\n",
    "        key: np.mean(values) for key, values in all_metrics.items()\n",
    "    }\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "print(\"Iniciando evaluación del modelo...\")\n",
    "metricas_promedio = evaluar_modelo(model, ds, device)\n",
    "\n",
    "print(\"\\n--- Resultados de la Evaluación (Promedio) ---\")\n",
    "print(f\"Coeficiente de Dice:    {metricas_promedio['dice']:.4f}\")\n",
    "print(f\"IoU (Jaccard):          {metricas_promedio['iou']:.4f}\")\n",
    "print(f\"Accuracy:               {metricas_promedio['accuracy']:.4f}\")\n",
    "print(f\"Precision:              {metricas_promedio['precision']:.4f}\")\n",
    "print(f\"Recall (Sensitivity):   {metricas_promedio['recall_sensitivity']:.4f}\")\n",
    "print(f\"Specificity:            {metricas_promedio['specificity']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
